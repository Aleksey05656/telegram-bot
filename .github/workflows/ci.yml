# @file: .github/workflows/ci.yml
# @description: CI workflow running linting and tests across Python versions with pip cache
# @dependencies: .pre-commit-config.yaml, requirements.txt
# @created: 2025-08-24

name: CI

env:
  APP_VERSION: v1.0.0-rc1
  GIT_SHA: ${{ github.sha }}
  BACKTEST_DAYS: 120

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"

jobs:
  assert-no-binaries:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: assert-no-binaries
        run: tools/ci_assert_no_binaries.sh

  offline-qa:
    runs-on: ubuntu-latest
    needs: assert-no-binaries
    env:
      USE_OFFLINE_STUBS: "1"
    steps:
      - uses: actions/checkout@v4

      - name: assert-no-binaries
        run: tools/ci_assert_no_binaries.sh

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install minimal test dependencies
        run: |
          python -m pip install -U pip
          python -m pip install pytest

      - name: pytest (offline stubs)
        run: pytest -q

  pipeline:
    runs-on: ubuntu-latest
    needs: assert-no-binaries
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m pip install ruff black isort pytest pytest-cov

      - name: lint
        run: |
          python -m ruff check .
          python -m black --check .
          python -m isort --check-only .

      - name: alerts-validate
        run: make alerts-validate
        continue-on-error: true

      - name: test-fast
        run: make test-fast

      - name: smoke
        run: make test-smoke

      - name: coverage
        run: make coverage-html

      - name: coverage-enforce
        run: python -m diagtools.coverage_enforce --summary-json reports/coverage_summary.json

      - name: reports
        run: |
          python reports/bot_e2e_snapshot.py
          python reports/rc_summary.py --tests-passed --summary-json reports/coverage_summary.json

      - name: artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-and-reports
          path: |
            htmlcov/**
            reports/bot_e2e_snapshot.md
            reports/rc_summary.json
            reports/coverage_summary.json
          retention-days: 14

  value-calibration-gate:
    runs-on: ubuntu-latest
    needs: pipeline
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
      REPORTS_DIR: ${{ runner.temp }}/value/reports
      DB_PATH: ${{ runner.temp }}/value/bot.sqlite3
      DATA_ROOT: ${{ runner.temp }}/value/data
      ENABLE_VALUE_FEATURES: "1"
      ODDS_PROVIDER: csv
      ODDS_FIXTURES_PATH: tests/fixtures/odds
      BACKTEST_DAYS: ${{ env.BACKTEST_DAYS }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run value calibration gate
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          mkdir -p "$REPORTS_DIR" "$DATA_ROOT"
          python -m diagtools.value_check --calibrate --days ${BACKTEST_DAYS}

      - name: Upload value calibration artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: value-calibration
          path: |
            ${{ env.REPORTS_DIR }}/diagnostics/value_calibration.json
            ${{ env.REPORTS_DIR }}/diagnostics/value_calibration.md
          retention-days: 7

  value-agg-clv-gate:
    runs-on: ubuntu-latest
    needs: pipeline
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
      REPORTS_DIR: ${{ runner.temp }}/value-agg-clv/diagnostics
      DB_PATH: ${{ runner.temp }}/value-agg-clv/bot.sqlite3
      DATA_ROOT: ${{ runner.temp }}/value-agg-clv/data
      ENABLE_VALUE_FEATURES: "1"
      ODDS_PROVIDERS: csv
      ODDS_PROVIDER_WEIGHTS: csv:1.0
      ODDS_PROVIDER: csv
      ODDS_AGG_METHOD: median
      ODDS_SNAPSHOT_RETENTION_DAYS: 14
      CLV_WINDOW_BEFORE_KICKOFF_MIN: 120
      CLV_FAIL_THRESHOLD_PCT: -5.0
      FIXTURES_ROOT: tests/fixtures/odds_multi
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Prepare SQLite schema
        run: |
          mkdir -p "$(dirname "$DB_PATH")" "$REPORTS_DIR" "$DATA_ROOT"
          sqlite3 "$DB_PATH" < database/schema.sql

      - name: Seed consensus ledger
        env:
          DB_PATH: ${{ env.DB_PATH }}
          FIXTURES_ROOT: ${{ env.FIXTURES_ROOT }}
          ODDS_AGG_METHOD: ${{ env.ODDS_AGG_METHOD }}
          ODDS_SNAPSHOT_RETENTION_DAYS: ${{ env.ODDS_SNAPSHOT_RETENTION_DAYS }}
          CLV_WINDOW_BEFORE_KICKOFF_MIN: ${{ env.CLV_WINDOW_BEFORE_KICKOFF_MIN }}
        run: |
          python - <<'PY'
          import csv
          import os
          from datetime import UTC, datetime, timedelta
          from pathlib import Path

          from app.lines.aggregator import LinesAggregator
          from app.lines.providers.base import OddsSnapshot
          from app.lines.storage import OddsSQLiteStore
          from app.value_clv import PicksLedgerStore
          from app.value_detector import ValuePick

          db_path = Path(os.environ["DB_PATH"]).resolve()
          fixtures_root = Path(os.environ.get("FIXTURES_ROOT", "tests/fixtures/odds_multi")).resolve()
          store = OddsSQLiteStore(db_path=str(db_path))
          aggregator = LinesAggregator(
              method=os.environ.get("ODDS_AGG_METHOD", "median"),
              provider_weights=None,
              store=store,
              retention_days=int(os.environ.get("ODDS_SNAPSHOT_RETENTION_DAYS", "14")),
              movement_window_minutes=int(os.environ.get("CLV_WINDOW_BEFORE_KICKOFF_MIN", "120")),
          )

          kickoff = datetime(2025, 10, 10, 20, 0, tzinfo=UTC)
          path = fixtures_root / "movement_closing.csv"

          def build_snapshot(row: dict[str, str]) -> OddsSnapshot:
              pulled = kickoff - timedelta(minutes=int(row["minutes_before"]))
              return OddsSnapshot(
                  provider=str(row["provider"]),
                  pulled_at=pulled,
                  match_key="m-agg",
                  league="EPL",
                  kickoff_utc=kickoff,
                  market="1X2",
                  selection="HOME",
                  price_decimal=float(row["price_decimal"]),
                  extra=None,
              )

          with path.open(encoding="utf-8") as fh:
              reader = csv.DictReader(fh)
              early_quotes = [build_snapshot(row) for row in reader if row["stage"] == "early"]
          aggregator.aggregate(early_quotes)
          with path.open(encoding="utf-8") as fh:
              reader = csv.DictReader(fh)
              closing_quotes = [build_snapshot(row) for row in reader if row["stage"] == "closing"]
          aggregator.aggregate(closing_quotes)

          ledger = PicksLedgerStore(db_path=str(db_path))
          for consensus in aggregator.last_metadata.values():
              pick = ValuePick(
                  match_key=consensus.match_key,
                  market=consensus.market,
                  selection=consensus.selection,
                  league=consensus.league or "EPL",
                  fair_price=float(consensus.price_decimal) * 0.95,
                  market_price=float(consensus.price_decimal) * 1.05,
                  edge_pct=7.0,
                  model_probability=0.55,
                  market_probability=float(consensus.probability),
                  confidence=0.8,
                  edge_weighted_pct=5.6,
                  edge_threshold_pct=3.0,
                  confidence_threshold=0.6,
                  calibrated=True,
                  provider="consensus",
                  pulled_at=consensus.pulled_at,
                  kickoff_utc=consensus.kickoff_utc,
              )
              ledger.record_pick(1, pick, consensus)
              ledger.record_closing_line(consensus)
              ledger.apply_closing_to_picks(consensus)
          PY

      - name: Run CLV gate
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          python -m diagtools.clv_check --db-path "$DB_PATH" --reports-dir "$REPORTS_DIR" --threshold "${CLV_FAIL_THRESHOLD_PCT}"

      - name: Upload CLV artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: value-agg-clv
          path: |
            ${{ env.REPORTS_DIR }}/value_clv.json
            ${{ env.REPORTS_DIR }}/value_clv.md
          retention-days: 7

  reliability-v2-gate:
    runs-on: ubuntu-latest
    needs: pipeline
    env:
      REPORTS_DIR: ${{ runner.temp }}/reliability/reports
      DB_PATH: ${{ runner.temp }}/reliability/bot.sqlite3
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Prepare provider stats fixture
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          python - <<'PY'
          import os
          import sqlite3
          from datetime import UTC, datetime, timedelta
          from pathlib import Path

          db_path = Path(os.environ["DB_PATH"]).resolve()
          db_path.parent.mkdir(parents=True, exist_ok=True)
          with sqlite3.connect(db_path) as conn:
              conn.execute(
                  """
                  CREATE TABLE provider_stats (
                      id INTEGER PRIMARY KEY AUTOINCREMENT,
                      provider TEXT NOT NULL,
                      league TEXT NOT NULL,
                      market TEXT NOT NULL,
                      samples INTEGER NOT NULL,
                      fresh_success INTEGER NOT NULL,
                      fresh_fail INTEGER NOT NULL,
                      latency_sum_ms REAL NOT NULL,
                      latency_sq_sum REAL NOT NULL,
                      stability_z_sum REAL NOT NULL,
                      stability_z_abs_sum REAL NOT NULL,
                      closing_within_tol INTEGER NOT NULL,
                      closing_total INTEGER NOT NULL,
                      score REAL NOT NULL,
                      updated_at_utc TEXT NOT NULL
                  )
                  """
              )
              conn.executemany(
                  """
                  INSERT INTO provider_stats (
                      provider, league, market, samples, fresh_success, fresh_fail,
                      latency_sum_ms, latency_sq_sum, stability_z_sum, stability_z_abs_sum,
                      closing_within_tol, closing_total, score, updated_at_utc
                  ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                  """,
                  [
                      (
                          "alpha",
                          "EPL",
                          "1X2",
                          480,
                          420,
                          60,
                          28000.0,
                          1.2e8,
                          0.0,
                          120.0,
                          18,
                          20,
                          0.82,
                          datetime.now(UTC).isoformat().replace("+00:00", "Z"),
                      ),
                      (
                          "beta",
                          "EPL",
                          "1X2",
                          350,
                          260,
                          90,
                          36000.0,
                          1.8e8,
                          0.0,
                          180.0,
                          12,
                          20,
                          0.58,
                          datetime.now(UTC).isoformat().replace("+00:00", "Z"),
                      ),
                  ],
              )
              conn.commit()
          PY

      - name: Run provider reliability gate
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          mkdir -p "$REPORTS_DIR"
          python -m diagtools.provider_quality \
            --db-path "$DB_PATH" \
            --reports-dir "$REPORTS_DIR" \
            --min-score 0.6 \
            --min-coverage 0.5 \
            --min-samples 200

      - name: Upload provider reliability artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reliability-v2
          path: |
            ${{ env.REPORTS_DIR }}/provider_quality.json
            ${{ env.REPORTS_DIR }}/provider_quality.md
          retention-days: 7

  amvera-smoke:
    name: amvera-smoke
    runs-on: ubuntu-latest
    needs: pipeline
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Smoke dry-run
        env:
          DB_PATH: ${{ runner.temp }}/amvera/bot.sqlite3
          REPORTS_DIR: ${{ runner.temp }}/amvera/reports
          LOG_DIR: ${{ runner.temp }}/amvera/logs
          MODEL_REGISTRY_PATH: ${{ runner.temp }}/amvera/artifacts
          PYTHONUNBUFFERED: "1"
          ENABLE_HEALTH: "1"
          HEALTH_PORT: "8080"
        run: |
          mkdir -p "$REPORTS_DIR" "$LOG_DIR" "$MODEL_REGISTRY_PATH"
          python -m main --dry-run

  diagnostics-v2:
    name: diagnostics-v2
    runs-on: ubuntu-latest
    needs: pipeline
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
      DRIFT_REF_DAYS: "90"
      DRIFT_PSI_WARN: "0.1"
      DRIFT_PSI_FAIL: "0.25"
      GOLDEN_COEF_EPS: "0.005"
      GOLDEN_LAMBDA_MAPE: "0.015"
      GOLDEN_PROB_EPS: "0.005"
      BENCH_P95_BUDGET_MS: "800"
      BENCH_ITER: "30"
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run diagnostics suite
        env:
          REPORTS_DIR: ${{ runner.temp }}/diag/reports
          LOG_DIR: ${{ runner.temp }}/diag/logs
          MODEL_REGISTRY_PATH: ${{ runner.temp }}/diag/artifacts
          RUNTIME_LOCK_PATH: ${{ runner.temp }}/diag/runtime.lock
        run: |
          mkdir -p "$REPORTS_DIR" "$LOG_DIR" "$MODEL_REGISTRY_PATH"
          pytest -q
          diag-run --all --reports-dir "$REPORTS_DIR"
          python -m diagtools.golden_regression --check --reports-dir "$REPORTS_DIR"
          diag-drift --reports-dir "$REPORTS_DIR/diagnostics/drift" --ref-days ${DRIFT_REF_DAYS} --ref-rolling-days ${DRIFT_ROLLING_DAYS:-30}
          python -m diagtools.bench --iterations ${BENCH_ITER} --reports-dir "$REPORTS_DIR/diagnostics/bench"

      - name: Upload diagnostics artefacts
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-v2
          path: ${{ runner.temp }}/diag/reports/diagnostics/**
          retention-days: 7

  diagnostics-drift:
    name: diagnostics-drift
    runs-on: ubuntu-latest
    needs: pipeline
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
      DRIFT_REF_DAYS: "90"
      DRIFT_ROLLING_DAYS: "30"
      DRIFT_PSI_WARN: "0.1"
      DRIFT_PSI_FAIL: "0.25"
      DRIFT_KS_P_WARN: "0.05"
      DRIFT_KS_P_FAIL: "0.01"
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run drift diagnostics
        env:
          REPORTS_DIR: ${{ runner.temp }}/drift/reports
        run: |
          mkdir -p "$REPORTS_DIR"
          diag-drift --reports-dir "$REPORTS_DIR" --ref-days "$DRIFT_REF_DAYS" --ref-rolling-days "$DRIFT_ROLLING_DAYS"

      - name: Upload drift artefacts
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-drift
          path: ${{ runner.temp }}/drift/reports/**
          retention-days: 7

  diagnostics-scheduled:
    name: diagnostics-scheduled
    runs-on: ubuntu-latest
    needs: pipeline
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    env:
      SPORTMONKS_STUB: "1"
      SPORTMONKS_API_KEY: dummy
      CI_DIAG_TRIGGER: ${{ github.event_name }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run diagnostics scheduler suite
        env:
          REPORTS_DIR: ${{ runner.temp }}/scheduled/reports
          LOG_DIR: ${{ runner.temp }}/scheduled/logs
          MODEL_REGISTRY_PATH: ${{ runner.temp }}/scheduled/artifacts
          RUNTIME_LOCK_PATH: ${{ runner.temp }}/scheduled/runtime.lock
        run: |
          mkdir -p "$REPORTS_DIR" "$LOG_DIR" "$MODEL_REGISTRY_PATH"
          python - <<'PY'
import os
from diagtools import scheduler

trigger = os.environ.get("CI_DIAG_TRIGGER", "ci")
scheduler.run_suite(trigger=trigger, reports_dir=os.environ["REPORTS_DIR"])
PY

      - name: Upload diagnostics dashboard
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-scheduled-site
          path: |
            ${{ runner.temp }}/scheduled/reports/diagnostics/site/**
            ${{ runner.temp }}/scheduled/reports/diagnostics/history/**
          if-no-files-found: warn
          retention-days: 7

  amvera-ops-v2-smoke:
    name: amvera-ops-v2-smoke
    runs-on: ubuntu-latest
    needs: pipeline
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Dry-run startup
        env:
          DB_PATH: ${{ runner.temp }}/amvera/bot.sqlite3
          REPORTS_DIR: ${{ runner.temp }}/amvera/reports
          LOG_DIR: ${{ runner.temp }}/amvera/logs
          MODEL_REGISTRY_PATH: ${{ runner.temp }}/amvera/artifacts
          PYTHONUNBUFFERED: "1"
          ENABLE_HEALTH: "1"
          ENABLE_METRICS: "1"
          ENABLE_POLLING: "0"
          HEALTH_PORT: "8080"
          METRICS_PORT: "8000"
        run: |
          mkdir -p "$REPORTS_DIR" "$LOG_DIR" "$MODEL_REGISTRY_PATH"
          python -m main --dry-run

      - name: Verify readiness and metrics
        env:
          DB_PATH: ${{ runner.temp }}/amvera/bot.sqlite3
          REPORTS_DIR: ${{ runner.temp }}/amvera/reports
          LOG_DIR: ${{ runner.temp }}/amvera/logs
          MODEL_REGISTRY_PATH: ${{ runner.temp }}/amvera/artifacts
          PYTHONUNBUFFERED: "1"
          ENABLE_HEALTH: "1"
          ENABLE_METRICS: "1"
          ENABLE_POLLING: "0"
          HEALTH_PORT: "8080"
          METRICS_PORT: "8000"
        run: |
          mkdir -p "$REPORTS_DIR" "$LOG_DIR" "$MODEL_REGISTRY_PATH"
          python -m main &
          PID=$!
          sleep 3
          curl -sf http://127.0.0.1:8080/health
          curl -sf http://127.0.0.1:8080/ready
          curl -sf http://127.0.0.1:8000/metrics > /tmp/metrics.txt
          head -n 5 /tmp/metrics.txt
          kill $PID
          wait $PID || true
