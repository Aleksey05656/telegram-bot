# scripts/train_model.py
"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Poisson-—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
import asyncio
import base64
import io
import json
import os
from datetime import datetime, timedelta
from typing import Any

import joblib  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from logger import logger
from ml.calibration import apply_calibration, calibrate_probs

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏
from ml.models.poisson_regression_model import PoissonRegressionModel, save_artifacts
from ml.modifiers_model import CalibrationLayer
from services.data_processor import DataProcessor
from services.sportmonks_client import sportmonks_client

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏
poisson_regression_model = PoissonRegressionModel(
    alpha=0.001, max_iter=300
)  # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã


def estimate_rho_from_history(samples):
    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤ –ø–æ —Ç–æ—Ç–∞–ª–∞–º/BTTS
    # –≤–µ—Ä–Ω–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ [0..min(lam_home, lam_away)]
    return float(
        np.clip(np.corrcoef(samples["resid_home"], samples["resid_away"])[0, 1], 0, 0.8)
    )


async def fetch_training_data(season_id: int = 23855) -> pd.DataFrame:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
    Args:
        season_id (int): ID —Å–µ–∑–æ–Ω–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    Returns:
        pd.DataFrame: –î–∞–Ω–Ω—ã–µ –æ –º–∞—Ç—á–∞—Ö
    """
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –°–µ–∑–æ–Ω ID: {season_id}")
        # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –º–∞—Ç—á–∞—Ö
        # –£–≤–µ–ª–∏—á–µ–Ω –ø–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: 730 –¥–Ω–µ–π (2 –≥–æ–¥–∞) –≤–º–µ—Å—Ç–æ 365
        two_years_ago = (datetime.now() - timedelta(days=730)).strftime("%Y-%m-%d")
        raw_data = await sportmonks_client.get_fixtures(
            season_id=season_id, next_fixtures=False, date_from=two_years_ago
        )
        if not raw_data:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –º–∞—Ç—á–∞—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
            return pd.DataFrame()
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(raw_data)} —Å—ã—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ –º–∞—Ç—á–∞—Ö.")
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ DataProcessor
        # –ü–†–ï–î–ü–û–õ–û–ñ–ï–ù–ò–ï: DataProcessor —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ,
        # –ø—Ä–∏–≥–æ–¥–Ω–æ–º –¥–ª—è prepare_features –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏.
        # –¢–æ –µ—Å—Ç—å, –∫–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:
        # home_team_id, away_team_id, home_goals, away_goals, league_id,
        # home_rest_days, away_rest_days, home_km_trip, away_km_trip,
        # home_xg, away_xg, home_xga, away_xga,
        # home_ppda, away_ppda, home_oppda, away_oppda,
        # home_mismatch, away_mismatch,
        # home_league_zscore_attack, away_league_zscore_attack,
        # home_league_zscore_defense, away_league_zscore_defense
        DataProcessor()
        # –ü–†–ï–î–ü–û–õ–û–ñ–ï–ù–ò–ï: –ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
        # processed_data = await processor.process_matches_data_for_poisson_model(raw_data)
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–¥–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å–ª—É—á–∞–µ, processor –¥–æ–ª–∂–µ–Ω –∑–∞–ø–æ–ª–Ω–∏—Ç—å —ç—Ç–∏ –ø–æ–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        processed_data = []
        for match in raw_data[:100]:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            if match.get("status") == "FT":  # –¢–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –º–∞—Ç—á–∏
                processed_data.append(
                    {
                        "home_team_id": match.get("home_team", {}).get("id", 0),
                        "away_team_id": match.get("away_team", {}).get("id", 0),
                        "home_goals": match.get("home_team", {}).get("goals", 0),
                        "away_goals": match.get("away_team", {}).get("goals", 0),
                        "date": match.get("date"),
                        "league_id": match.get("league_id", 0),
                        # --- –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –∫–æ–≤–∞—Ä–∏–∞—Ç—ã ---
                        "home_rest_days": match.get("home_team", {}).get(
                            "rest_days", 3.0
                        ),
                        "away_rest_days": match.get("away_team", {}).get(
                            "rest_days", 3.0
                        ),
                        "home_km_trip": match.get("home_team", {}).get("km_trip", 0.0),
                        "away_km_trip": match.get("away_team", {}).get("km_trip", 0.0),
                        "home_xg": match.get("home_team", {}).get("xg", 1.5),
                        "away_xg": match.get("away_team", {}).get("xg", 1.2),
                        "home_xga": match.get("home_team", {}).get(
                            "xga", 1.2
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º xga
                        "away_xga": match.get("away_team", {}).get(
                            "xga", 1.5
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º xga
                        "home_ppda": match.get("home_team", {}).get("ppda", 10.0),
                        "away_ppda": match.get("away_team", {}).get("ppda", 10.0),
                        "home_oppda": match.get("home_team", {}).get(
                            "oppda", 8.0
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º oppda
                        "away_oppda": match.get("away_team", {}).get(
                            "oppda", 8.0
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º oppda
                        "home_mismatch": match.get("home_team", {}).get(
                            "mismatch", 0.1
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º mismatch
                        "away_mismatch": match.get("away_team", {}).get(
                            "mismatch", 0.1
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º mismatch
                        "home_league_zscore_attack": match.get("home_team", {}).get(
                            "league_zscore_attack", 0.5
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º
                        "away_league_zscore_attack": match.get("away_team", {}).get(
                            "league_zscore_attack", 0.5
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º
                        "home_league_zscore_defense": match.get("home_team", {}).get(
                            "league_zscore_defense", -0.3
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º
                        "away_league_zscore_defense": match.get("away_team", {}).get(
                            "league_zscore_defense", -0.3
                        ),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º
                    }
                )
        if not processed_data:
            logger.warning("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø—É—Å—Ç—ã.")
            return pd.DataFrame()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_data)} –º–∞—Ç—á–µ–π.")
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = pd.DataFrame(processed_data)
        logger.info(f"–°–æ–∑–¥–∞–Ω DataFrame —Å {len(df)} –∑–∞–ø–∏—Å—è–º–∏.")
        return df
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {e}", exc_info=True)
        return pd.DataFrame()


async def validate_training_data(data: pd.DataFrame) -> bool:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
    Args:
        data (pd.DataFrame): –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    Returns:
        bool: True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã
    """
    try:
        if data.empty:
            logger.error("–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: –ø—É—Å—Ç–æ–π DataFrame")
            return False
        # –ù–æ–≤—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = [
            "home_team_id",
            "away_team_id",
            "home_goals",
            "away_goals",
            "league_id",
            "date",
            "home_rest_days",
            "away_rest_days",
            "home_km_trip",
            "away_km_trip",
            "home_xg",
            "away_xg",
            "home_xga",
            "away_xga",
            "home_ppda",
            "away_ppda",
            "home_oppda",
            "away_oppda",
            "home_mismatch",
            "away_mismatch",
            "home_league_zscore_attack",
            "away_league_zscore_attack",
            "home_league_zscore_defense",
            "away_league_zscore_defense",
        ]
        for col in required_columns:
            if col not in data.columns:
                logger.error(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ {col}")
                return False
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
        if len(data) < 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Ç—á–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            logger.warning(
                f"–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(data)} –º–∞—Ç—á–µ–π. –ú–∏–Ω–∏–º—É–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 50."
            )
            # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º
        else:
            logger.info(f"–î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(data)} –º–∞—Ç—á–µ–π.")
        logger.info("–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return False


def calculate_log_likelihood(
    predictions: list[float], actual_goals: list[int]
) -> float:
    """–†–∞—Å—á–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.
    Args:
        predictions (List[float]): –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (Œª)
        actual_goals (List[int]): –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≥–æ–ª—ã
    Returns:
        float: –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ
    """
    try:
        # –ò–∑–±–µ–≥–∞–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ –æ—Ç –Ω—É–ª—è
        epsilon = 1e-10
        log_likelihood = 0.0
        for pred, actual in zip(predictions, actual_goals, strict=False):
            pred = max(pred, epsilon)  # –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω—É–ª—è
            # –î–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ü—É–∞—Å—Å–æ–Ω–∞: log(P(k)) = k*log(Œª) - Œª - log(k!)
            # –£–ø—Ä–æ—â–µ–Ω–Ω–æ: log_likelihood += actual * np.log(pred) - pred
            log_likelihood += actual * np.log(pred) - pred
        return log_likelihood
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è: {e}")
        return float("-inf")


# –§—É–Ω–∫—Ü–∏–∏ validate_ewma_half_life –∏ optimize_ewma_half_life –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å xg/ppda –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ –æ–Ω–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤ –º–æ–¥–µ–ª—å
async def validate_ewma_half_life(data: pd.DataFrame, half_life_days: float) -> float:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ half_life –¥–ª—è EWMA —á–µ—Ä–µ–∑ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é.
    Args:
        data (pd.DataFrame): –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        half_life_days (float): –ü–µ—Ä–∏–æ–¥ –ø–æ–ª—É—Ä–∞—Å–ø–∞–¥–∞ –≤ –¥–Ω—è—Ö
    Returns:
        float: –°—Ä–µ–¥–Ω–µ–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ
    """
    try:
        logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏—è EWMA —Å half_life = {half_life_days} –¥–Ω–µ–π")
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (80/20)
        split_idx = int(len(data) * 0.8)
        train_data = data.iloc[:split_idx]
        test_data = data.iloc[split_idx:]
        if len(test_data) == 0:
            logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return float("-inf")
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ xG —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º EWMA
        # –ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, —Å–æ–∑–¥–∞–µ–º –∏–º–∏—Ç–∞—Ü–∏—é
        # –ò–º–∏—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ EWMA)
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è xg –∫–∞–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        home_predictions = [train_data["home_xg"].mean()] * len(
            test_data
        )  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–∏–π xG
        away_predictions = [train_data["away_xg"].mean()] * len(test_data)
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ
        home_ll = calculate_log_likelihood(
            home_predictions, test_data["home_goals"].tolist()
        )
        away_ll = calculate_log_likelihood(
            away_predictions, test_data["away_goals"].tolist()
        )
        avg_ll = (home_ll + away_ll) / 2
        logger.info(
            f"–°—Ä–µ–¥–Ω–µ–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ –¥–ª—è half_life {half_life_days}: {avg_ll:.4f}"
        )
        return avg_ll
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ EWMA —Å half_life {half_life_days}: {e}")
        return float("-inf")


async def optimize_ewma_half_life(
    data: pd.DataFrame, half_life_range: list[float] = None
) -> tuple[float, float]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ half_life –¥–ª—è EWMA —á–µ—Ä–µ–∑ —Å–µ—Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫.
    Args:
        data (pd.DataFrame): –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        half_life_range (List[float]): –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
    Returns:
        Tuple[float, float]: (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ half_life, –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏)
    """
    try:
        if half_life_range is None:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 7 –¥–æ 90 –¥–Ω–µ–π
            half_life_range = [7, 14, 30, 45, 60, 90, 120]
        logger.info(f"–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ EWMA half_life –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {half_life_range}")
        best_half_life = 30.0  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        best_score = float("-inf")
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        for half_life in half_life_range:
            score = await validate_ewma_half_life(data, half_life)
            if score > best_score:
                best_score = score
                best_half_life = half_life
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: half_life = {best_half_life}, score = {best_score:.4f}"
                )
        logger.info(
            f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ half_life: {best_half_life}"
        )
        return best_half_life, best_score
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ EWMA half_life: {e}")
        return 30.0, float("-inf")  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é


async def expanding_window_cv(
    data: pd.DataFrame, n_splits: int = 5
) -> dict[str, float]:
    """
    –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å —Ä–∞—Å—à–∏—Ä—è—é—â–∏–º—Å—è –æ–∫–Ω–æ–º –¥–ª—è –Ω–æ–≤–æ–π PoissonRegressionModel.
    Args:
        data (pd.DataFrame): –î–∞–Ω–Ω—ã–µ, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ
        n_splits (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏–π
    Returns:
        Dict[str, float]: –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    """
    try:
        logger.info(f"–ó–∞–ø—É—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å {n_splits} —Ä–∞–∑–±–∏–µ–Ω–∏—è–º–∏")
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ
        data_sorted = data.sort_values("date").reset_index(drop=True)
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        log_losses = []
        brier_scores = []
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –æ–∫–æ–Ω
        total_size = len(data_sorted)
        initial_train_size = total_size // 3  # –ù–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–∞—é—â–µ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ ~33%
        step_size = (total_size - initial_train_size) // n_splits
        if step_size <= 0:
            logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return {"mean_log_loss": float("inf"), "mean_brier_score": float("inf")}
        for i in range(n_splits):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –æ–±—É—á–∞—é—â–µ–≥–æ –∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤
            train_end = initial_train_size + i * step_size
            test_start = train_end
            test_end = min(train_end + step_size, total_size)
            if test_start >= test_end:
                continue
            # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            train_data = data_sorted.iloc[:train_end].copy()
            test_data = data_sorted.iloc[test_start:test_end].copy()
            logger.debug(
                f"Fold {i+1}: train [{0}:{train_end}], test [{test_start}:{test_end}]"
            )
            # --- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ train_data ---
            try:
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–æ–ª–¥–∞
                temp_model = PoissonRegressionModel(alpha=0.001, max_iter=300)
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                asyncio.get_event_loop()
                train_success = await temp_model.train_model(train_data)
                if not train_success:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è fold {i+1}")
                    log_losses.append(float("inf"))
                    brier_scores.append(float("inf"))
                    continue
                # --- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ test_data ---
                predicted_home_lambdas = []
                predicted_away_lambdas = []
                for _, row in test_data.iterrows():
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ calculate_base_lambda –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—è–º–±–¥—ã
                    lambda_home, lambda_away = temp_model.calculate_base_lambda(
                        home_team_id=row["home_team_id"],
                        away_team_id=row["away_team_id"],
                        league_id=row["league_id"],
                        home_rest_days=row["home_rest_days"],
                        away_rest_days=row["away_rest_days"],
                        home_km_trip=row["home_km_trip"],
                        away_km_trip=row["away_km_trip"],
                        home_xg=row["home_xg"],
                        away_xg=row["away_xg"],
                        home_xga=row["home_xga"],
                        away_xga=row["away_xga"],
                        home_ppda=row["home_ppda"],
                        away_ppda=row["away_ppda"],
                        home_oppda=row["home_oppda"],
                        away_oppda=row["away_oppda"],
                        home_mismatch=row["home_mismatch"],
                        away_mismatch=row["away_mismatch"],
                        home_league_zscore_attack=row["home_league_zscore_attack"],
                        away_league_zscore_attack=row["away_league_zscore_attack"],
                        home_league_zscore_defense=row["home_league_zscore_defense"],
                        away_league_zscore_defense=row["away_league_zscore_defense"],
                    )
                    predicted_home_lambdas.append(lambda_home)
                    predicted_away_lambdas.append(lambda_away)
                # --- –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ ---
                actual_home_goals = test_data["home_goals"].tolist()
                actual_away_goals = test_data["away_goals"].tolist()
                # Log Loss –¥–ª—è Poisson —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                try:
                    home_ll = calculate_log_likelihood(
                        predicted_home_lambdas, actual_home_goals
                    )
                    away_ll = calculate_log_likelihood(
                        predicted_away_lambdas, actual_away_goals
                    )
                    log_loss_value = (
                        -(home_ll + away_ll) / 2
                    )  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏
                    log_losses.append(log_loss_value)
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ log loss –¥–ª—è fold {i+1}: {e}")
                    log_losses.append(float("inf"))
                # Brier Score (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
                # –ü—Ä–∏–º–µ—Ä: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–±–µ–¥—ã –¥–æ–º–∞—à–Ω–µ–π –∫–æ–º–∞–Ω–¥—ã –∫–∞–∫ P(Poisson(lambda_home) > Poisson(lambda_away))
                # –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π. –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤–æ–∑—å–º–µ–º —Ä–∞–∑–Ω–∏—Ü—É.
                try:
                    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: sigmoid —Ä–∞–∑–Ω–∏—Ü—ã –ª—è–º–±–¥
                    diff_lambdas = np.array(predicted_home_lambdas) - np.array(
                        predicted_away_lambdas
                    )
                    prob_home_win_simplified = 1 / (
                        1 + np.exp(-diff_lambdas)
                    )  # Sigmoid
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–∏–Ω–Ω—ã–µ –∏—Å—Ö–æ–¥—ã (1 –µ—Å–ª–∏ –ø–æ–±–µ–¥–∞ –¥–æ–º–∞—à–Ω–µ–π, 0 –∏–Ω–∞—á–µ)
                    y_true_binary = (
                        np.array(actual_home_goals) > np.array(actual_away_goals)
                    ).astype(int)
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Brier Score
                    if len(y_true_binary) > 0 and len(prob_home_win_simplified) == len(
                        y_true_binary
                    ):
                        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ [0, 1]
                        prob_home_win_simplified = np.clip(
                            prob_home_win_simplified, 1e-15, 1 - 1e-15
                        )
                        brier_score_value = np.mean(
                            (prob_home_win_simplified - y_true_binary) ** 2
                        )
                        brier_scores.append(brier_score_value)
                    else:
                        raise ValueError(
                            "–ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–∞—Å—Å–∏–≤–æ–≤ –¥–ª—è Brier Score"
                        )
                except Exception as e:
                    logger.warning(
                        f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ Brier score –¥–ª—è fold {i+1}: {e}"
                    )
                    brier_scores.append(float("inf"))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏/–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –¥–ª—è fold {i+1}: {e}")
                log_losses.append(float("inf"))
                brier_scores.append(float("inf"))
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        mean_log_loss = np.mean(log_losses) if log_losses else float("inf")
        mean_brier_score = np.mean(brier_scores) if brier_scores else float("inf")
        logger.info(
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: "
            f"Log Loss = {mean_log_loss:.4f}, "
            f"Brier Score = {mean_brier_score:.4f}"
        )
        return {
            "mean_log_loss": mean_log_loss,
            "mean_brier_score": mean_brier_score,
            "fold_count": len(
                [ll for ll in log_losses if ll != float("inf")]
            ),  # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —Ñ–æ–ª–¥—ã
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        return {"mean_log_loss": float("inf"), "mean_brier_score": float("inf")}


def save_metrics_report(path: str, metrics_dict: dict[str, Any]) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤ JSON —Ñ–∞–π–ª.
    Args:
        path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        metrics_dict (Dict[str, Any]): –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    Returns:
        bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(
            os.path.dirname(path) if os.path.dirname(path) else ".", exist_ok=True
        )
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON —Ñ–∞–π–ª
        with open(path, "w", encoding="utf-8") as f:
            json.dump(metrics_dict, f, indent=2, ensure_ascii=False, default=str)
        logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path}")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –≤ {path}: {e}")
        return False


def generate_calibration_curve_plot(
    y_true: np.ndarray, y_prob: np.ndarray, n_bins: int = 10
) -> str | None:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π –∏ –≤–æ–∑–≤—Ä–∞—Ç –≤ –≤–∏–¥–µ base64 —Å—Ç—Ä–æ–∫–∏.
    Args:
        y_true (np.ndarray): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        y_prob (np.ndarray): –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        n_bins (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–Ω–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
    Returns:
        Optional[str]: Base64 —Å—Ç—Ä–æ–∫–∞ —Å –≥—Ä–∞—Ñ–∏–∫–æ–º –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        if n_bins <= 0:
            logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–Ω–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π")
            return None
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∏–Ω—ã
        bin_bounds = np.linspace(0, 1, n_bins + 1)
        bin_lowers = bin_bounds[:-1]
        bin_uppers = bin_bounds[1:]
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∏–Ω–∞
        bin_accuracies = []
        bin_confidences = []
        bin_counts = []
        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers, strict=False):
            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ç–µ–∫—É—â–µ–º –±–∏–Ω–µ
            in_bin = (y_prob > bin_lower) & (y_prob <= bin_upper)
            prop_in_bin = in_bin.mean()
            bin_counts.append(prop_in_bin)
            if prop_in_bin > 0:
                # –¢–æ—á–Ω–æ—Å—Ç—å –≤ –±–∏–Ω–µ
                accuracy_in_bin = y_true[in_bin].mean()
                # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –±–∏–Ω–µ
                avg_confidence_in_bin = y_prob[in_bin].mean()
                bin_accuracies.append(accuracy_in_bin)
                bin_confidences.append(avg_confidence_in_bin)
            else:
                bin_accuracies.append(0)
                bin_confidences.append(0)
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.plot(bin_confidences, bin_accuracies, "s-", label="–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –∫—Ä–∏–≤–∞—è")
        ax.plot([0, 1], [0, 1], "k:", label="–ò–¥–µ–∞–ª—å–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞")
        ax.set_xlabel("–°—Ä–µ–¥–Ω—è—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
        ax.set_ylabel("–î–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏—Å—Ö–æ–¥–æ–≤")
        ax.set_title("–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –∫—Ä–∏–≤–∞—è")
        ax.legend()
        ax.grid(True)
        # –î–æ–±–∞–≤–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –∫–∞–∂–¥–æ–º –±–∏–Ω–µ
        ax2 = ax.twinx()
        ax2.bar(
            bin_lowers,
            bin_counts,
            width=1.0 / n_bins,
            alpha=0.3,
            color="gray",
            align="edge",
        )
        ax2.set_ylabel("–î–æ–ª—è –æ–±—Ä–∞–∑—Ü–æ–≤", color="gray")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ base64
        buffer = io.BytesIO()
        plt.savefig(buffer, format="png", bbox_inches="tight")
        buffer.seek(0)
        plot_base64 = base64.b64encode(buffer.getvalue()).decode()
        plt.close(fig)
        logger.debug("–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –∫—Ä–∏–≤–∞—è —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
        return plot_base64
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π: {e}")
        return None


async def train_model(data: pd.DataFrame):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    Args:
        data (pd.DataFrame): –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    try:
        logger.info(
            "üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –æ–±—É—á–µ–Ω–∏—è Poisson-—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)"
        )
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        if not await validate_training_data(data):
            logger.error("–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞. –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
            return
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ half_life –¥–ª—è EWMA
        logger.info("–ù–∞—á–∞–ª–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ half_life –¥–ª—è EWMA")
        optimal_half_life, best_score = await optimize_ewma_half_life(data)
        logger.info(
            f"–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ half_life –¥–ª—è EWMA: {optimal_half_life} –¥–Ω–µ–π (score: {best_score:.4f})"
        )
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        logger.info("–ù–∞—á–∞–ª–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        cv_metrics = await expanding_window_cv(data, n_splits=5)
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: {cv_metrics}")
        # --- –û–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ ---
        logger.info("–û–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π Poisson-—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–æ–≤—ã–π –º–µ—Ç–æ–¥)
        train_success = await poisson_regression_model.train_model(data)
        if not train_success:
            logger.error("–û–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π.")
            return
        else:
            logger.info("–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞.")
        # --- –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ---
        logger.info("–ù–∞—á–∞–ª–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        # –∏–∑ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–ª–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ.
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —ç—Ç–æ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        # –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–æ–ª–¥–∞ CV.
        # –°–æ–∑–¥–∞–¥–∏–º –∏–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        np.random.seed(42)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        # –ò–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–±–µ–¥–∞ –¥–æ–º–∞—à–Ω–µ–π –∫–æ–º–∞–Ω–¥—ã)
        sample_true = np.random.binomial(1, 0.45, 1000)  # 45% –ø–æ–±–µ–¥ –¥–æ–º–∞—à–Ω–∏—Ö
        # –ò–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ "—Å—ã—Ä—ã–µ" –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–¥–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏)
        # –î–æ–±–∞–≤–∏–º —à—É–º –∫ –∏—Å—Ç–∏–Ω–Ω—ã–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ –∏–¥–µ–∞–ª—å–Ω–æ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞
        true_probs = 0.45 + 0.1 * (np.random.rand(1000) - 0.5)  # –í–∞—Ä–∏–∞—Ü–∏–∏ –≤–æ–∫—Ä—É–≥ 0.45
        # –î–æ–±–∞–≤–∏–º —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É (overconfidence)
        sample_pred_raw = np.clip(
            true_probs + np.random.normal(0, 0.1, 1000), 0.01, 0.99
        )
        # –û–±—É—á–∞–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –Ω–∞ –∏–º–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        calibrator = calibrate_probs(sample_true, sample_pred_raw)
        if calibrator is not None:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∫ —Ç–µ–º –∂–µ "—Å—ã—Ä—ã–º" –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            calibrated_probs = apply_calibration(calibrator, sample_pred_raw)
            logger.info(
                f"–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞. –°—Ä–µ–¥–Ω–µ–µ –¥–æ: {np.mean(sample_pred_raw):.4f}, "
                f"–ø–æ—Å–ª–µ: {np.mean(calibrated_probs):.4f}"
            )
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—É—é –∫—Ä–∏–≤—É—é
            calibration_plot = generate_calibration_curve_plot(
                sample_true, sample_pred_raw
            )
            if calibration_plot:
                logger.info("–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –∫—Ä–∏–≤–∞—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
            else:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—É—é –∫—Ä–∏–≤—É—é")
        else:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä")
            calibrator = None
            calibration_plot = None
        # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞ ---
        model_save_path = "data/models/poisson_regression"
        meta_data = {
            "training_timestamp": datetime.now().isoformat(),
            "optimal_ewma_half_life": optimal_half_life,
            "cv_metrics": cv_metrics,
        }
        save_artifacts(poisson_regression_model, model_save_path, meta_data)
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {model_save_path}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä —Ä—è–¥–æ–º —Å –º–æ–¥–µ–ª—å—é
        if calibrator is not None:
            calibrator_path = f"{model_save_path}_calibrator.joblib"
            try:
                joblib.dump(calibrator, calibrator_path)
                logger.info(f"‚úÖ –ö–∞–ª–∏–±—Ä–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {calibrator_path}")
            except Exception as save_cal_error:
                logger.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞ –≤ {calibrator_path}: {save_cal_error}"
                )
        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---
        metrics_report = {
            "training_timestamp": datetime.now().isoformat(),
            "data_statistics": {
                "total_matches": len(data),
                "date_range": {
                    "from": data["date"].min() if "date" in data.columns else None,
                    "to": data["date"].max() if "date" in data.columns else None,
                },
                "unique_teams": len(
                    set(data["home_team_id"].tolist() + data["away_team_id"].tolist())
                )
                if "home_team_id" in data.columns and "away_team_id" in data.columns
                else 0,
                "unique_leagues": data["league_id"].nunique()
                if "league_id" in data.columns
                else 0,
            },
            "cross_validation": cv_metrics,
            "ewma_optimization": {
                "optimal_half_life": optimal_half_life,
                "best_score": best_score,
            },
            "model_parameters": {  # –ó–∞–≥–ª—É—à–∫–∞, —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
                "alpha": poisson_regression_model.alpha,
                "max_iter": poisson_regression_model.max_iter,
                "feature_names": poisson_regression_model.feature_names,
            },
            "calibration": {"calibration_curves": {}},
        }
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ
        if calibration_plot:
            metrics_report["calibration"]["calibration_curves"][
                "sample"
            ] = calibration_plot
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        metrics_path = f"data/metrics/model_metrics_{timestamp}.json"
        save_success = save_metrics_report(metrics_path, metrics_report)
        if save_success:
            logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metrics_path}")
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è")
        logger.info(
            "‚úÖ Poisson-—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã."
        )
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}", exc_info=True)


# --- –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø RQ ---
def train_and_persist(season_id: int | None = None):
    """
    –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ RQ.
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π, —Ç–∞–∫ –∫–∞–∫ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è RQ.
    –í–Ω—É—Ç—Ä–∏ –æ–Ω–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –ª–æ–≥–∏–∫—É.
    Args:
        season_id (Optional[int]): ID —Å–µ–∑–æ–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
    """
    try:
        logger.info(
            f"–ù–∞—á–∞–ª–æ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ RQ (—Å–µ–∑–æ–Ω ID: {season_id})"
        )
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event loop –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è
        loop.run_until_complete(_async_train_and_persist(season_id))
        loop.close()
        logger.info("‚úÖ –ó–∞–¥–∞—á–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ RQ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        logger.error(
            f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ RQ: {e}", exc_info=True
        )
        raise  # –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã RQ –º–æ–≥ –µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –∑–∞–ø–∏—Å–∞—Ç—å –≤ failed jobs


async def _async_train_and_persist(season_id: int | None = None):
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ª–æ–≥–∏–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è."""
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    # TODO: –ó–∞–º–µ–Ω–∏—Ç–µ season_id –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π ID —Å–µ–∑–æ–Ω–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if season_id is None:
        season_id = 23855  # –ü—Ä–∏–º–µ—Ä: Premier League 2023/2024 (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π)
    training_data = await fetch_training_data(season_id=season_id)
    if training_data.empty:
        logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ –∑–∞–¥–∞—á–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.")
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    await train_model(training_data)
    logger.info("üèÅ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —á–∞—Å—Ç—å –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


# --- –ö–û–ù–ï–¶ –ù–û–í–û–ô –§–£–ù–ö–¶–ò–ò –î–õ–Ø RQ ---
async def main():
    """–ì–ª–∞–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Å–∫—Ä–∏–ø—Ç–∞ –æ–±—É—á–µ–Ω–∏—è."""
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –æ–±—É—á–µ–Ω–∏—è Poisson-—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        # TODO: –ó–∞–º–µ–Ω–∏—Ç–µ season_id –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π ID —Å–µ–∑–æ–Ω–∞
        season_id = 23855  # –ü—Ä–∏–º–µ—Ä: Premier League 2023/2024
        training_data = await fetch_training_data(season_id=season_id)
        if training_data.empty:
            logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            return
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        await train_model(training_data)
        logger.info("üèÅ –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ: {e}", exc_info=True)


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    asyncio.run(main())

# 6. –û–±—É—á–µ–Ω–∏–µ: —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ö–µ–ª–ø–µ—Ä –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
# 6.1. –î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü train_model.py (append)
from typing import Any

import numpy as np
import pandas as pd

try:
    from config import settings
except Exception:
    from config import get_settings as _gs

    settings = _gs()
try:
    from poisson_regression_model import PoissonRegressionModel
except Exception:
    PoissonRegressionModel = None
from data_processor import (
    build_features,
    compute_time_decay_weights,
    make_time_series_splits,
)

DEFAULT_ALPHA_GRID = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0]


def _ensure_models_dir(
    league: str | None, market: str | None, version: str | None
) -> str:
    base = getattr(settings, "MODELS_DIR", "models")
    ver = (
        version
        or getattr(settings, "MODEL_VERSION", None)
        or "v" + datetime.utcnow().strftime("%Y%m%d")
    )
    path = os.path.join(base, str(league) if league else "", market, ver)
    os.makedirs(path, exist_ok=True)
    return path


def train_league_market(
    league: str,
    market: str,
    df: pd.DataFrame,
    *,
    date_col: str = "match_date",
    target_cols: dict[str, str] = None,
    feature_cols: list[str] | None = None,
    alphas: list[float] | None = None,
    version: str | None = None,
) -> dict[str, str]:
    target_cols = target_cols or {
        "home_goals": "home_goals",
        "away_goals": "away_goals",
    }
    alphas = alphas or DEFAULT_ALPHA_GRID

    X = build_features(df)
    w = compute_time_decay_weights(
        df,
        date_col=date_col,
        half_life_days=getattr(settings, "TIME_DECAY_HALFLIFE_DAYS", 180),
    )
    splits = make_time_series_splits(
        df,
        date_col=date_col,
        n_splits=getattr(settings, "CV_N_SPLITS", 6),
        min_train_days=getattr(settings, "CV_MIN_TRAIN_DAYS", 120),
        gap_days=getattr(settings, "CV_GAP_DAYS", 0),
    )
    if feature_cols is None:
        feature_cols = [
            c
            for c in X.columns
            if c not in (target_cols["home_goals"], target_cols["away_goals"], date_col)
        ]

    saved: dict[str, str] = {}
    outdir = _ensure_models_dir(league, market, version)

    # Base Poisson
    if PoissonRegressionModel is not None:
        model = PoissonRegressionModel()
        try:
            model.fit_time_series_cv(
                df=X.assign(
                    y_home=df[target_cols["home_goals"]],
                    y_away=df[target_cols["away_goals"]],
                ),
                features=feature_cols,
                target_col=target_cols["home_goals"],
                ts_splits=splits,
                alphas=alphas,
                sample_weight=w,
            )
        except Exception:
            model.fit(X[feature_cols], df[target_cols["home_goals"]], sample_weight=w)
        try:
            model.save_artifacts(outdir)
        except Exception:
            joblib.dump(model, os.path.join(outdir, "base_model.joblib"))
        saved["base"] = os.path.join(outdir, "base_model.joblib")

    # Œª-Calibration
    modifier = CalibrationLayer(feature_names=feature_cols, alpha=1.0)
    modifier.fit(
        X[feature_cols],
        y_home=df[target_cols["home_goals"]].to_numpy(),
        y_away=df[target_cols["away_goals"]].to_numpy(),
        lam_home_base=np.clip((df[target_cols["home_goals"]].mean() or 1.0), 1e-6, None)
        * np.ones(len(df)),
        lam_away_base=np.clip((df[target_cols["away_goals"]].mean() or 1.0), 1e-6, None)
        * np.ones(len(df)),
        sample_weight=w,
    )
    modp = os.path.join(outdir, "modifier.joblib")
    modifier.save(modp)
    saved["modifier"] = modp

    # Meta (–∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –Ω–∞ —à–∞–≥ –ø–æ–∑–∂–µ, –∫–æ–≥–¥–∞ –±—É–¥—É—Ç —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏ —Ä—ã–Ω–∫–æ–≤)
    with open(os.path.join(outdir, "meta.json"), "w", encoding="utf-8") as f:
        json.dump(
            {
                "league": str(league),
                "market": str(market),
                "version": os.path.basename(outdir),
                "timestamp": datetime.utcnow().isoformat(),
            },
            f,
            ensure_ascii=False,
            indent=2,
        )

    return saved
