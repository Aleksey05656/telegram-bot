"""
Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð²ÐµÑ€ÑÐ¸ÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸.
Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚ --model-version. Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð°Ð´Ð°Ð½ â€” Ð²ÐµÑ€ÑÐ¸Ñ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¿Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ
Ð¸Ð· config.MODEL_VERSION_FORMAT (fallback: %Y%m%d%H%M%S), Ð´Ð°Ð»ÐµÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ÑÑ Ð² .env
Ð¸ Ð² Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ models/model_version.txt, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ†ÐµÐ¿Ð¾Ñ‡ÐºÐ° Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ â†’ Ð´ÐµÐ¿Ð»Ð¾Ð¹ Ð±Ñ‹Ð»Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾Ð¹.
"""
import argparse
import asyncio
import os
from datetime import datetime
from pathlib import Path

import pandas as pd

from config import get_settings
from logger import logger
from scripts.train_model import train_league_market


def _generate_model_version(fmt: str | None) -> str:
    fmt = fmt or "%Y%m%d%H%M%S"
    try:
        return f"v{datetime.now().strftime(fmt)}"
    except Exception:
        return f"v{datetime.now().strftime('%Y%m%d%H%M%S')}"


def _update_env_file(env_path: Path, key: str, value: str) -> None:
    """ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð¸Ð»Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ key=value Ð² .env."""
    env_path.parent.mkdir(parents=True, exist_ok=True)
    lines: list[str] = []
    if env_path.exists():
        lines = env_path.read_text(encoding="utf-8").splitlines()
    out: list[str] = []
    found = False
    for line in lines:
        if not line.strip() or line.strip().startswith("#"):
            out.append(line)
            continue
        if line.split("=", 1)[0].strip() == key:
            out.append(f"{key}={value}")
            found = True
        else:
            out.append(line)
    if not found:
        out.append(f"{key}={value}")
    env_path.write_text("\n".join(out) + "\n", encoding="utf-8")


def _persist_model_version_artifacts(version: str, models_dir: Path) -> None:
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð²ÐµÑ€ÑÐ¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ (models/model_version.txt)."""
    models_dir.mkdir(parents=True, exist_ok=True)
    (models_dir / "model_version.txt").write_text(version + "\n", encoding="utf-8")


def parse_args() -> argparse.Namespace:
    """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸."""
    parser = argparse.ArgumentParser(
        description="Run training pipeline with explicit model versioning."
    )
    parser.add_argument(
        "--model-version",
        type=str,
        default=None,
        help="Ð¯Ð²Ð½Ð¾ Ð·Ð°Ð´Ð°Ñ‚ÑŒ Ð²ÐµÑ€ÑÐ¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, v20250823). Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð°Ð´Ð°Ð½Ð¾ â€” ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸.",
    )
    return parser.parse_args()


async def run_training_pipeline(
    datasets: dict[int, pd.DataFrame], min_matches_threshold: int = 1500
) -> None:
    """
    Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð»Ð¸Ð³.
    Args:
        datasets (Dict[int, pd.DataFrame]): Ð”Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð»Ð¸Ð³Ð¸
        min_matches_threshold (int): ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹ Ð´Ð»Ñ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð»Ð¸Ð³Ð¸
    """
    try:
        logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð»Ð¸Ð³Ð¸ Ð½Ð° ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ðµ Ð¸ Ð¼ÐµÐ»ÐºÐ¸Ðµ
        large_leagues = {}  # Ð›Ð¸Ð³Ð¸ Ñ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        small_leagues = {}  # Ð›Ð¸Ð³Ð¸ Ñ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        for league_id, df in datasets.items():
            if len(df) >= min_matches_threshold:
                large_leagues[league_id] = df
                logger.info(f"Ð›Ð¸Ð³Ð° {league_id} ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° ÐºÐ°Ðº ÐºÑ€ÑƒÐ¿Ð½Ð°Ñ ({len(df)} Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹)")
            else:
                small_leagues[league_id] = df
                logger.info(f"Ð›Ð¸Ð³Ð° {league_id} ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° ÐºÐ°Ðº Ð¼ÐµÐ»ÐºÐ°Ñ ({len(df)} Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹)")
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ Ð¼ÐµÐ»ÐºÐ¸Ñ… Ð»Ð¸Ð³
        global_dataset = None
        if small_leagues:
            small_dfs = list(small_leagues.values())
            global_dataset = pd.concat(small_dfs, ignore_index=True)
            logger.info(f"Ð¡Ð¾Ð·Ð´Ð°Ð½ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð´Ð»Ñ Ð¼ÐµÐ»ÐºÐ¸Ñ… Ð»Ð¸Ð³: {len(global_dataset)} Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹")
        # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… Ð»Ð¸Ð³
        markets = ["1x2", "btts", "ou_2_5"]
        for league_id, df_league in large_leagues.items():
            logger.info(f"ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ Ð»Ð¸Ð³Ð¸ {league_id}")
            for market in markets:
                try:
                    logger.info(f"ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð»Ð¸Ð³Ð¸ {league_id}, Ñ€Ñ‹Ð½Ð¾Ðº {market}")
                    # Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
                    saved_paths = train_league_market(
                        league=str(league_id),
                        market=market,
                        df=df_league,
                        date_col="match_date",
                    )
                    logger.info(
                        f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð»Ð¸Ð³Ð¸ {league_id}, Ñ€Ñ‹Ð½Ð¾Ðº {market} Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð°. "
                        f"Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹: {list(saved_paths.keys())}"
                    )
                except Exception as e:
                    logger.error(
                        f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð»Ð¸Ð³Ð¸ {league_id}, Ñ€Ñ‹Ð½Ð¾Ðº {market}: {e}"
                    )
                    continue
        # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¼ÐµÐ»ÐºÐ¸Ñ… Ð»Ð¸Ð³
        if global_dataset is not None and not global_dataset.empty:
            logger.info("ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð¼ÐµÐ»ÐºÐ¸Ñ… Ð»Ð¸Ð³")
            for market in markets:
                try:
                    logger.info(f"ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ñ€Ñ‹Ð½ÐºÐ° {market}")
                    # Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ league="_global"
                    saved_paths = train_league_market(
                        league="_global",
                        market=market,
                        df=global_dataset,
                        date_col="match_date",
                    )
                    logger.info(
                        f"Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ€Ñ‹Ð½ÐºÐ° {market} Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð°. "
                        f"Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹: {list(saved_paths.keys())}"
                    )
                except Exception as e:
                    logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ñ€Ñ‹Ð½ÐºÐ° {market}: {e}")
                    continue
        logger.info("ðŸ ÐŸÐ°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½")
    except Exception as e:
        logger.error(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ: {e}", exc_info=True)


# === ÐšÐžÐÐ•Ð¦ ÐÐžÐ’ÐžÐ“Ðž ÐšÐžÐ”Ð Ð”Ð›Ð¯ Ð­Ð¢ÐÐŸÐ 9.2 ===


async def async_main() -> None:
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ."""
    try:
        logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ (Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð»Ð¸ Ð‘Ð”)
        datasets: dict[int, pd.DataFrame] = {}  # Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ Ð·Ð´ÐµÑÑŒ
        if not datasets:
            logger.warning("ÐÐµÑ‚ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒÑ‚Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹.")
            return
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        await run_training_pipeline(datasets, min_matches_threshold=1500)
        logger.info("ðŸ ÐŸÐ°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½")
    except Exception as e:
        logger.error(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ: {e}", exc_info=True)


def main() -> None:
    args = parse_args()
    settings = get_settings()
    model_version = args.model_version or _generate_model_version(
        getattr(settings, "MODEL_VERSION_FORMAT", "%Y%m%d%H%M%S")
    )
    _update_env_file(Path(".env"), "MODEL_VERSION", model_version)
    models_dir = Path(getattr(settings, "MODELS_DIR", "models"))
    _persist_model_version_artifacts(model_version, models_dir)
    os.environ["MODEL_VERSION"] = model_version
    asyncio.run(async_main())


if __name__ == "__main__":
    main()
